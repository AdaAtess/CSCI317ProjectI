{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCI317Project1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNywoGYvrCebeLT16gIOEQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdaAtess/CSCI317ProjectI/blob/main/CSCI317Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contribution Notes\n",
        "\n",
        "This Colab notebook consists of resources, my thought process, bits of my code, example codes that could fix the mentioned issue, and my contribution notes."
      ],
      "metadata": {
        "id": "KIEGoAMwSg2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a small tutorial to see if I understand how to use TensorFlow in a basic way from a user's perspective."
      ],
      "metadata": {
        "id": "ksT6XvsSOuKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.add(1, 2).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-3bTkpqLHfl",
        "outputId": "75fcd4bb-aef4-42c0-b63c-01dfcc38484c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "hello.numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEFzSZEwLND5",
        "outputId": "e8f2480c-4d88-41df-810e-810abdfee075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello, TensorFlow!'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The website of TensorFlow was a little complicated to find where to start from. There were a lot of sub-sections to go through as TensorFlow is very much well-established at this point and the community is unbelievably big.\n",
        "\n",
        "I couldn't find any tutorials on how to conntribute or which issues/projects are the most crucial to contribute to. On the other hand, there were a lot of tutorials about how to use TensorFlow (beginner vs. experts) as well as free courses on Machine Learning. These seem quite interesting.\n",
        "\n",
        "I kept exploring the website for contributions, there seemed to be a lot of ways to contribute -- groups, forums, blogs -- but it was pretty unclear where and how to start. When I found the \"Contribute\" sub-section under \"Community,\" there was a \"good first issue\" and \"contributions welcome\" links. As I am an inexperienced open source software developer, I went along with \"good first issue.\" However, when I followed the link, I saw that the issues were closed and have been closed for about 3 years. I saw some comments that suggested many people experienced the same problem as I did, as they were comments such as: \"Hey, I'm a first time contributor, is this somewhere I can start from?\" or \"I really want to help but this issue seems closed, where can I contribute from\" etc. \n",
        "\n",
        "I searched around a little bit more; however, I found it quite hard to start somewhere as the directions they point to were all sort of dead ends. \n",
        "\n",
        "Then, I decided to move to \"Issues\" section in GitHub repo of TensorFlow and decided to tackle a problem there.\n",
        "\n",
        "Overall, I would say it was a frustrating experience. You want to contribute and as you go on the website and follow the directions, you end up at dead ends. It sort of takes away from your eagerness and I have seen people voicing the same issue as I have experienced."
      ],
      "metadata": {
        "id": "lT2OXv_lO34O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow GitHub repo, I found this issue about an additional math operations functionality. TF1 is wanted to be supported by hex to see tensors in hex version. TF2 supports this feature but TF1 doesn't. The person who started this issue was using TF1 did not necessarily want to migrate to TF2 and wanted an easier solution. Here is the github code pointed in discussion \"[Feature] To support casting float32 to int32 in HEX format #30493\":\n",
        "https://github.com/tensorflow/tensorflow/issues/30493"
      ],
      "metadata": {
        "id": "cO4Vrf6kIAC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the code seems to create a problem:\n",
        "\n",
        "https://github.com/tensorflow/tensorflow/blob/v2.7.0/tensorflow/python/ops/math_ops.py#L938-L1007\n"
      ],
      "metadata": {
        "id": "vyMjmrXiI59v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf_export(\"cast\", \"dtypes.cast\")\n",
        "@dispatch.register_unary_elementwise_api\n",
        "@dispatch.add_dispatch_support\n",
        "def cast(x, dtype, name=None):\n",
        "  \"\"\"Casts a tensor to a new type.\n",
        "  The operation casts `x` (in case of `Tensor`) or `x.values`\n",
        "  (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
        "  For example:\n",
        "  >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
        "  >>> tf.cast(x, tf.int32)\n",
        "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
        "  Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
        "  >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
        "  >>> tf.dtypes.cast(x, tf.int32)\n",
        "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
        "  The operation supports data types (for `x` and `dtype`) of\n",
        "  `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
        "  `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
        "  In case of casting from complex types (`complex64`, `complex128`) to real\n",
        "  types, only the real part of `x` is returned. In case of casting from real\n",
        "  types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
        "  returned value is set to `0`. The handling of complex types here matches the\n",
        "  behavior of numpy.\n",
        "  Note casting nan and inf values to integral types has undefined behavior.\n",
        "  Args:\n",
        "    x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
        "      be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
        "      `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
        "      `bfloat16`.\n",
        "    dtype: The destination type. The list of supported dtypes is the same as\n",
        "      `x`.\n",
        "    name: A name for the operation (optional).\n",
        "  Returns:\n",
        "    A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
        "      same type as `dtype`.\n",
        "  Raises:\n",
        "    TypeError: If `x` cannot be cast to the `dtype`.\n",
        "  \"\"\"\n",
        "  base_type = dtypes.as_dtype(dtype).base_dtype\n",
        "  if isinstance(x,\n",
        "                (ops.Tensor, _resource_variable_type)) and base_type == x.dtype:\n",
        "    return x\n",
        "  with ops.name_scope(name, \"Cast\", [x]) as name:\n",
        "    if isinstance(x, sparse_tensor.SparseTensor):\n",
        "      values_cast = cast(x.values, base_type, name=name)\n",
        "      x = sparse_tensor.SparseTensor(x.indices, values_cast, x.dense_shape)\n",
        "    elif isinstance(x, ops.IndexedSlices):\n",
        "      values_cast = cast(x.values, base_type, name=name)\n",
        "      x = ops.IndexedSlices(values_cast, x.indices, x.dense_shape)\n",
        "    else:\n",
        "      # TODO(josh11b): If x is not already a Tensor, we could return\n",
        "      # ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\n",
        "      # allows some conversions that cast() can't do, e.g. casting numbers to\n",
        "      # strings.\n",
        "      x = ops.convert_to_tensor(x, name=\"x\")\n",
        "      if x.dtype.base_dtype != base_type:\n",
        "        x = gen_math_ops.cast(x, base_type, name=name)\n",
        "    if x.dtype.is_complex and base_type.is_floating:\n",
        "      logging.warn(\"Casting complex to real discards imaginary part.\")\n",
        "    return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "SOs5duOCI9wC",
        "outputId": "8c1d5330-3330-4494-b428-7f6283309679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-db33f802264d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtypes.cast\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_unary_elementwise_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \"\"\"Casts a tensor to a new type.\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf_export' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example solution on TensorFlow website published more recently compared to the issue's opening.\n",
        "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/bitcast"
      ],
      "metadata": {
        "id": "iPfFA6bdNbIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "xs4HSJB8Hdbo",
        "outputId": "9b32abcd-3e08-4087-fae5-69b0237de174"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-360a1ee329de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tf.bitcast(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "tf.bitcast(\n",
        "    input, type, name=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a tensor input, this operation returns a tensor that has the same buffer data as input with datatype type.\n",
        "\n",
        "If the input datatype T is larger than the output datatype type then the shape changes from [...] to [..., sizeof(T)/sizeof(type)].\n",
        "\n",
        "If T is smaller than type, the operator requires that the rightmost dimension be equal to sizeof(type)/sizeof(T). The shape then goes from [..., sizeof(type)/sizeof(T)] to [...].\n",
        "\n",
        "tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast() gives module error. For example,\n",
        "\n",
        "**Example 1:**"
      ],
      "metadata": {
        "id": "p3v1_a4XHtFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1., 2., 3.]\n",
        "equality_bitcast = tf.bitcast(a,tf.complex128)\n",
        "\n",
        "equality_cast = tf.cast(a,tf.complex128)\n",
        "print(equality_cast)"
      ],
      "metadata": {
        "id": "lhp-p-ZqHhja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:**"
      ],
      "metadata": {
        "id": "jULHCEUaH2YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)\n",
        "<tf.Tensor: ... shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>\n"
      ],
      "metadata": {
        "id": "aQ4PZGLEHncm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3:**"
      ],
      "metadata": {
        "id": "DmTwIJMsH667"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> x = [1., 2., 3.]\n",
        ">>> y = [0., 2., 3.]\n",
        ">>> equality= tf.equal(x,y)\n",
        ">>> equality_cast = tf.cast(equality,tf.float32)\n",
        ">>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)\n",
        ">>> print(equality)\n",
        "tf.Tensor([False True True], shape=(3,), dtype=bool)\n",
        ">>> print(equality_cast)\n",
        "tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)\n",
        ">>> print(equality_bitcast)\n",
        "tf.Tensor(\n",
        "[[ 0 0 0 0]\n",
        " [ 0 0 128 63]\n",
        " [ 0 0 128 63]], shape=(3, 4), dtype=uint8)"
      ],
      "metadata": {
        "id": "RWk48Sc4HpuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the person's problem was about TF1 and TF2 creating differences and hence hex not being able to be used as wanted. I was doing some research and thinking on how to solve this issue, I came across a very recent article that was published with the most recent update of TensorFlow which could solve this problem.\n",
        "https://www.tensorflow.org/api_docs/python/tf/io/decode_raw\n",
        "\n",
        "The possible solution suggested in the article:"
      ],
      "metadata": {
        "id": "2GcVzmS3J26S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(\n",
        "    input_bytes, out_type, little_endian=True, fixed_length=None, name=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "x6xIyr5PJ6EY",
        "outputId": "55055976-aa96-4971-cce8-2e6baa317b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4f7d1373f95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.io.decode_raw(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlittle_endian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_bytes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)\n",
        "\n",
        "tf.io.decode_raw(tf.constant(\"1,2\"), tf.uint8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFCam8b4MFXH",
        "outputId": "278ccea0-ea13-43c9-eb7e-c218a779610e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=uint8, numpy=array([49, 44, 50], dtype=uint8)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant([\"1\",\"2\"]), tf.uint8).shape\n",
        "\n",
        "tf.io.decode_raw(tf.constant([[\"1\"],[\"2\"]]), tf.uint8).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNBUYKrMGDX",
        "outputId": "88e6c48b-f282-4c88-d9e0-40f8753db177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant(\"123\"), tf.uint8)\n",
        "\n",
        "tf.io.decode_raw(tf.constant(\"1234\"), tf.uint8)\n",
        "\n",
        "# chuncked output\n",
        "tf.io.decode_raw(tf.constant(\"12\"), tf.uint16)\n",
        "\n",
        "tf.io.decode_raw(tf.constant(\"1234\"), tf.uint16)\n",
        "\n",
        "# int64 output\n",
        "tf.io.decode_raw(tf.constant(\"12345678\"), tf.int64)\n",
        "\n",
        "tf.io.decode_raw(tf.constant(\"1234567887654321\"), tf.int64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETNhK6ngMIl4",
        "outputId": "ddfabbdf-620d-4846-f47d-bc24dccf3707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4050765991979987505, 3544952156018063160])>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant(\"\\x0a\\x0b\"), tf.int16)\n",
        "\n",
        "hex(2826)\n",
        "\n",
        "tf.io.decode_raw(tf.constant(\"\\x0a\\x0b\"), tf.int16, little_endian=False)\n",
        "\n",
        "hex(2571)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VYNLLH9aMNNB",
        "outputId": "c077c217-1227-40a3-83d3-f20a52cde138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0xa0b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant([[\"1\"],[\"23\"]]), tf.uint8, fixed_length=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COwz42kQMOsn",
        "outputId": "d51a0d16-0a71-4424-abfa-11496b745614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 4), dtype=uint8, numpy=\n",
              "array([[[49,  0,  0,  0]],\n",
              "\n",
              "       [[50, 51,  0,  0]]], dtype=uint8)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rR9kju-MQ2V",
        "outputId": "e7c94104-3b77-4fd3-b694-c4d44b274ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], dtype=uint16)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=''.join([chr(1), chr(2), chr(3), chr(4)])\n",
        "tf.io.decode_raw(x, tf.uint16, fixed_length=2)\n",
        "\n",
        "hex(513)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I7xEqQTzMTQ0",
        "outputId": "395e746f-153d-4695-c3ce-66a12848dc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0x201'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=''.join([chr(1), chr(2), chr(3), chr(4)])\n",
        "tf.io.decode_raw(x, tf.uint16, fixed_length=2, little_endian=False)\n",
        "\n",
        "hex(258)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RjSSVIfCMYmA",
        "outputId": "189f23d9-dab9-4942-eae5-3893be703914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0x102'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"12345678\", \"87654321\"]\n",
        "tf.io.decode_raw(x, tf.int16)\n",
        "\n",
        "\n",
        "\n",
        "tf.io.decode_raw(x, tf.int16, fixed_length=len(x[0]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVXvJnyAMZRB",
        "outputId": "4e47b041-995b-4ec2-ca1a-c240c4c12b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n",
              "array([[12849, 13363, 13877, 14391],\n",
              "       [14136, 13622, 13108, 12594]], dtype=int16)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code  below is in the source code of TF2. I realized the person was asking for help without migrating to TF2. I think this could be of help. I saw that there is a recent functionality called -- tf2.convert_to_tf1 -- that could be used after using the below to achieve hex code. Or the above functions that would work in TF1 as well. TensorFlow seem to have fixed this issue. I was not sure if I should reply to the person and point to these resources as it has been a while since this issue was discussed as it was opened in 2019 and nothing has been seem to be published for some time.\n",
        "\n",
        "Note. These source codes were pretty hard to find. The documentation inside the files are very detailed and easy to follow; however, the files themselves are hard to find and they don't necessarily have explanations on why they exist and what their specific purpose in the general source code is. The general documentation isn't as clear as much as it should be in my opinion."
      ],
      "metadata": {
        "id": "yB4pwfK9Mx8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code below is from: https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/python/ops/parsing_ops.py#L842-L974"
      ],
      "metadata": {
        "id": "_3bBxWT2Rrgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf_export(\"io.decode_raw\", v1=[])\n",
        "@dispatch.add_dispatch_support\n",
        "def decode_raw(input_bytes,\n",
        "               out_type,\n",
        "               little_endian=True,\n",
        "               fixed_length=None,\n",
        "               name=None):\n",
        "  r\"\"\"Convert raw bytes from input tensor into numeric tensors.\n",
        "  Every component of the input tensor is interpreted as a sequence of bytes.\n",
        "  These bytes are then decoded as numbers in the format specified by `out_type`.\n",
        "  >>> tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)\n",
        "  <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>\n",
        "  >>> tf.io.decode_raw(tf.constant(\"1,2\"), tf.uint8)\n",
        "  <tf.Tensor: shape=(3,), dtype=uint8, numpy=array([49, 44, 50], dtype=uint8)>\n",
        "  Note that the rank of the output tensor is always one more than the input one:\n",
        "  >>> tf.io.decode_raw(tf.constant([\"1\",\"2\"]), tf.uint8).shape\n",
        "  TensorShape([2, 1])\n",
        "  >>> tf.io.decode_raw(tf.constant([[\"1\"],[\"2\"]]), tf.uint8).shape\n",
        "  TensorShape([2, 1, 1])\n",
        "  This is because each byte in the input is converted to a new value on the\n",
        "  output (if output type is `uint8` or `int8`, otherwise chunks of inputs get\n",
        "  coverted to a new value):\n",
        "  >>> tf.io.decode_raw(tf.constant(\"123\"), tf.uint8)\n",
        "  <tf.Tensor: shape=(3,), dtype=uint8, numpy=array([49, 50, 51], dtype=uint8)>\n",
        "  >>> tf.io.decode_raw(tf.constant(\"1234\"), tf.uint8)\n",
        "  <tf.Tensor: shape=(4,), dtype=uint8, numpy=array([49, 50, 51, 52], ...\n",
        "  >>> # chuncked output\n",
        "  >>> tf.io.decode_raw(tf.constant(\"12\"), tf.uint16)\n",
        "  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([12849], dtype=uint16)>\n",
        "  >>> tf.io.decode_raw(tf.constant(\"1234\"), tf.uint16)\n",
        "  <tf.Tensor: shape=(2,), dtype=uint16, numpy=array([12849, 13363], ...\n",
        "  >>> # int64 output\n",
        "  >>> tf.io.decode_raw(tf.constant(\"12345678\"), tf.int64)\n",
        "  <tf.Tensor: ... numpy=array([4050765991979987505])>\n",
        "  >>> tf.io.decode_raw(tf.constant(\"1234567887654321\"), tf.int64)\n",
        "  <tf.Tensor: ... numpy=array([4050765991979987505, 3544952156018063160])>\n",
        "  The operation allows specifying endianness via the `little_endian` parameter.\n",
        "  >>> tf.io.decode_raw(tf.constant(\"\\x0a\\x0b\"), tf.int16)\n",
        "  <tf.Tensor: shape=(1,), dtype=int16, numpy=array([2826], dtype=int16)>\n",
        "  >>> hex(2826)\n",
        "  '0xb0a'\n",
        "  >>> tf.io.decode_raw(tf.constant(\"\\x0a\\x0b\"), tf.int16, little_endian=False)\n",
        "  <tf.Tensor: shape=(1,), dtype=int16, numpy=array([2571], dtype=int16)>\n",
        "  >>> hex(2571)\n",
        "  '0xa0b'\n",
        "  If the elements of `input_bytes` are of different length, you must specify\n",
        "  `fixed_length`:\n",
        "  >>> tf.io.decode_raw(tf.constant([[\"1\"],[\"23\"]]), tf.uint8, fixed_length=4)\n",
        "  <tf.Tensor: shape=(2, 1, 4), dtype=uint8, numpy=\n",
        "  array([[[49,  0,  0,  0]],\n",
        "         [[50, 51,  0,  0]]], dtype=uint8)>\n",
        "  If the `fixed_length` value is larger that the length of the `out_type` dtype,\n",
        "  multiple values are generated:\n",
        "  >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=4)\n",
        "  <tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], ...\n",
        "  If the input value is larger than `fixed_length`, it is truncated:\n",
        "  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n",
        "  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2)\n",
        "  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([513], dtype=uint16)>\n",
        "  >>> hex(513)\n",
        "  '0x201'\n",
        "  If `little_endian` and `fixed_length` are specified, truncation to the fixed\n",
        "  length occurs before endianness conversion:\n",
        "  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n",
        "  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2, little_endian=False)\n",
        "  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([258], dtype=uint16)>\n",
        "  >>> hex(258)\n",
        "  '0x102'\n",
        "  If input values all have the same length, then specifying `fixed_length`\n",
        "  equal to the size of the strings should not change output:\n",
        "  >>> x = [\"12345678\", \"87654321\"]\n",
        "  >>> tf.io.decode_raw(x, tf.int16)\n",
        "  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n",
        "  array([[12849, 13363, 13877, 14391],\n",
        "         [14136, 13622, 13108, 12594]], dtype=int16)>\n",
        "  >>> tf.io.decode_raw(x, tf.int16, fixed_length=len(x[0]))\n",
        "  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n",
        "  array([[12849, 13363, 13877, 14391],\n",
        "         [14136, 13622, 13108, 12594]], dtype=int16)>\n",
        "  Args:\n",
        "    input_bytes:\n",
        "      Each element of the input Tensor is converted to an array of bytes.\n",
        "      Currently, this must be a tensor of strings (bytes), although semantically\n",
        "      the operation should support any input.\n",
        "    out_type:\n",
        "      `DType` of the output. Acceptable types are `half`, `float`, `double`,\n",
        "      `int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.\n",
        "    little_endian:\n",
        "      Whether the `input_bytes` data is in little-endian format. Data will be\n",
        "      converted into host byte order if necessary.\n",
        "    fixed_length:\n",
        "      If set, the first `fixed_length` bytes of each element will be converted.\n",
        "      Data will be zero-padded or truncated to the specified length.\n",
        "      `fixed_length` must be a multiple of the size of `out_type`.\n",
        "      `fixed_length` must be specified if the elements of `input_bytes` are of\n",
        "      variable length.\n",
        "    name: A name for the operation (optional).\n",
        "  Returns:\n",
        "    A `Tensor` object storing the decoded bytes.\n",
        "  \"\"\"\n",
        "  if fixed_length is not None:\n",
        "    return gen_parsing_ops.decode_padded_raw(\n",
        "        input_bytes,\n",
        "        fixed_length=fixed_length,\n",
        "        out_type=out_type,\n",
        "        little_endian=little_endian,\n",
        "        name=name)\n",
        "  else:\n",
        "    return gen_parsing_ops.decode_raw(\n",
        "        input_bytes, out_type, little_endian=little_endian, name=name)"
      ],
      "metadata": {
        "id": "Ltzy14NbMwac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, finding a place to start from was a hard and frustrating process. It is not as welcoming as they make it out to be for first-time contributors. However, there is a plethora of resources and places of discussion, the community seems to be tight and helpful. It was nice to see people interact, not dismiss questions/comments as \"unworthy\" or \"basic\", and be of help to everyone."
      ],
      "metadata": {
        "id": "DtLm4DIAR5Kd"
      }
    }
  ]
}